{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omargrojas/ADA-2023/blob/main/ds-leadscore-tutorial-activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DRo4XF8HxuG"
      },
      "source": [
        " # Data Science 101 - Lead Scoring Scenario"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYioZ4DtHxuJ"
      },
      "source": [
        "## Part 1: Problem\n",
        "\n",
        "Today we are going to look at a very common data science problem found in e-commerce and web based software or services (like Xero!). **Lead scoring!**\n",
        "\n",
        "### The Sales Process\n",
        "\n",
        "An education company named X Education sells online courses to industry professionals. On any given day, many professionals who are interested in the courses land on their website and browse for courses.\n",
        "\n",
        "1. Individuals land on the website, they might browse the courses, watch some videos and if they are interested they will fill up a form for the course.\n",
        "\n",
        "1. Once individuals fill out a form, they have now become a potential customer or **lead**\n",
        "\n",
        "1. Employees from the sales team will contact leads by emailing or calling them with the goal of getting the lead to sign up for the course - called a **conversion**\n",
        "\n",
        "We will be using a consulting model called \"SCQA\" to help break down the problem.\n",
        "\n",
        "### Situation\n",
        "\n",
        "- Currently only 38% of leads contacted go on to become a paying customer.\n",
        "- The CEO wants to grow the customer base by 20% over the next year\n",
        "\n",
        "### Complication\n",
        "\n",
        "- The head of the sales & advertising department has marketing budget to increase advertising and generate 20% more leads, but does not have the headcount to contact every lead already, so more leads would not necessarily mean more conversions\n",
        "- The department head knows that a conversion rate of 38% means a lot of time and money is wasted on customers who never intended to sign up.\n",
        "\n",
        "### Question\n",
        "\n",
        "- How can data science help to convert more leads with the same or less amount of calls?\n",
        "\n",
        "### Answer\n",
        "\n",
        "- A lead scoring model trained on historical conversion data could help us to prioritise leads and form a better queue to call from 'hottest' lead to 'coldest'\n",
        "\n",
        "Your idea for a lead scoring model gets approved - now you need to look at the data you and decide what model you are going to build!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjNRwAjhHxuK"
      },
      "source": [
        "## Part 2: Tools\n",
        "\n",
        "Today we are going to be using a few different tools in our lead scoring scenario:\n",
        "\n",
        "### Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdLNMSCIHxuL"
      },
      "outputs": [],
      "source": [
        "# some basic python commands\n",
        "\n",
        "# create an array\n",
        "x = [1, 2, 3, 4, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy6nU6_THxuN"
      },
      "outputs": [],
      "source": [
        "# try the print command print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EozNAtbGHxuN"
      },
      "outputs": [],
      "source": [
        "# try min(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trkcG3KeHxuO"
      },
      "outputs": [],
      "source": [
        "# try max(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6S1tx8AHxuO"
      },
      "source": [
        "`min`, `max` and `print` are what we call **functions**. These are preprogrammed commands to do common calculations on manipulations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8zTb0x4HxuP"
      },
      "source": [
        "### Jupyter Notebook in Google Colab\n",
        "\n",
        "Jupyter notebook contains **cells** to run each bit of code at a time\n",
        "\n",
        "You can run a cell by using `ctrl` + `enter`\n",
        "\n",
        "Or because we are hosting the notebook in Google Colab you can click the `play` button at the top of the cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gw5EiaCHxuP"
      },
      "source": [
        "You can add a new text or code cell using the buttons at the top of the notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5D88rVqHxuP"
      },
      "source": [
        "### Importing packages\n",
        "\n",
        "To do data science we need to add a bit more functionality than is available in the base python code.\n",
        "\n",
        "We do this by importing packages that have extra functions for data analysis, statistics and machine learning.\n",
        "\n",
        "The data scientists tool kit generally includes the following packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oanyMkzUHxuQ"
      },
      "outputs": [],
      "source": [
        "# package for multi-dimensional arrays and matrices\n",
        "import numpy as np\n",
        "\n",
        "# package for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# packages for creating plots and graphs\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# visulaisation\n",
        "from matplotlib.pyplot import xticks\n",
        "%matplotlib inline\n",
        "\n",
        "# ignoring any warnings for this tutorial and you should absolutely ignore warnings forever wait I mean\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCbKOPsMHxuQ"
      },
      "source": [
        "We use the `import` function to load the extra functions into our python session.\n",
        "\n",
        "The `as` just shortens the path name of the function so we can call `pd.function_name()` instead of `pandas.function_name()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AHpk_TAHxuQ"
      },
      "source": [
        "## Part 3: Load Data\n",
        "\n",
        "We use functions from the `pandas` package to load in our data from a csv. Then it's important to check that we have loaded the data correctly!\n",
        "\n",
        "Because the datasets are normally too large to parse all at once we can't just browse it like a spreadsheet. We use functions instead to browse the data, looking at the number of records and the content stored in each column.\n",
        "\n",
        "It's also very useful to look at the type of data in each column and check for any duplicates or missing/Null values. Doing this up front will save us headaches later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJVGpn1WHxuQ"
      },
      "outputs": [],
      "source": [
        "# read in the data into a pandas dataframe\n",
        "leads_df = pd.read_csv('https://raw.githubusercontent.com/hjamau/ds-leadscore-tutorial/master/Leads.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wiTihtbHxuR"
      },
      "outputs": [],
      "source": [
        "# class of the object\n",
        "type(leads_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XM_XvbPHxuR"
      },
      "outputs": [],
      "source": [
        "# how many rows and columns\n",
        "leads_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5aZhvn3HxuR"
      },
      "outputs": [],
      "source": [
        "# top 10 rows of the dataframe df.head()\n",
        "leads_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fCjg0L_HxuR"
      },
      "outputs": [],
      "source": [
        "# bottom 5 rows of the dataframe try df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBDHy_pDHxuR"
      },
      "outputs": [],
      "source": [
        "# describe\n",
        "leads_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA32g6zeHxuS"
      },
      "outputs": [],
      "source": [
        "leads_df.describe(include = 'all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNubflNHxuS"
      },
      "outputs": [],
      "source": [
        "# column names\n",
        "leads_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8Gm6QREHxuS"
      },
      "outputs": [],
      "source": [
        "# selecting columns\n",
        "leads_df.Specialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cGEDGnGHxuS"
      },
      "outputs": [],
      "source": [
        "# this also selects a column\n",
        "leads_df['Specialization']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_YFB6odHxuS"
      },
      "outputs": [],
      "source": [
        "# We can also subset a dataframe to specific columns\n",
        "leads_df[['Specialization', 'Converted']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb7koP0LHxuS"
      },
      "outputs": [],
      "source": [
        "# We can apply functions over columns. Try sum() on the Converted column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWstQf_cHxuT"
      },
      "outputs": [],
      "source": [
        "# We can do multiple functions in one command\n",
        "# letâ€™s use the converted column, sum and shape functions to check existing conversion rate in data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gu1Or-aHxuT"
      },
      "outputs": [],
      "source": [
        "# Let's use the sum and duplicated functions to do a very important step - check duplicates\n",
        "leads_df.duplicated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBDWbRXkHxuT"
      },
      "outputs": [],
      "source": [
        "# use sum() and dumplicated to get the count of duplicated columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G3OukmOHxuT"
      },
      "outputs": [],
      "source": [
        "# look at null/missing values\n",
        "leads_df.isnull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm0LhyyRHxuT"
      },
      "outputs": [],
      "source": [
        "# use sum() and isnull() to get count of null values accross the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9t-EM2GHHxuU"
      },
      "outputs": [],
      "source": [
        "# Use value counts to look at the levels and counts of categories\n",
        "leads_df.Specialization.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfSpde2gHxuU"
      },
      "outputs": [],
      "source": [
        "# Try with another column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Nv9erLHxuU"
      },
      "source": [
        "## Part 4: Data Cleaning\n",
        "\n",
        "In the real world we often have imperfect or missing data that we need to 'clean' to get ready for data analysis.\n",
        "\n",
        "Using what we learnt above about the data, we will now apply some changes to the dataframe to fill in any gaps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCS_2_ceHxuU"
      },
      "outputs": [],
      "source": [
        "# There are \"select\" values in columns, that doesn't make any sense for specialization (I know it's a Z not an S its American)\n",
        "# This is because customer did not select any option from the list and the form was built badly, hence it shows select.\n",
        "\n",
        "# Change 'Select' values to NaN.\n",
        "leads_df = leads_df.replace('Select', np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dheXy-4HHxuU"
      },
      "outputs": [],
      "source": [
        "# lets look at the specialization column again\n",
        "leads_df['Specialization'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g0O269sHxuU"
      },
      "outputs": [],
      "source": [
        "# It maybe the case that the lead has not entered any specialization if their option is not availabe on the list\n",
        "# We can make a category \"Others\" for missing values.\n",
        "leads_df['Specialization'] = leads_df['Specialization'].replace(np.nan, 'Other')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xSCRgC2HxuV"
      },
      "outputs": [],
      "source": [
        "# lets look at the specialization column again\n",
        "leads_df['Specialization'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELo8-6LcHxuV"
      },
      "source": [
        "## Part 5: Data Exploration\n",
        "\n",
        "Each row in our data is a single observation made up of a values in each column.\n",
        "\n",
        "Now we have cleaned the data we can start exploring each of the columns we have as **variables** in the dataset:\n",
        "\n",
        "- `Prospect ID` is the identifier variable for the data across each row\n",
        "\n",
        "- `converted`  is our **target** variable (also known as the response variable) i.e. the variable that we are interested in predicting.\n",
        "\n",
        "    - It is binary and the event either happens or it doesn't i.e. 0 or 1\n",
        "\n",
        "- We have a mix of 7 categorical and continuous variables we can as **predictor** variables (also called explanatory variable, feature, input variable or independent variable)\n",
        "\n",
        "We can explore the data to see if there are any correlations between the target and predictor variables.\n",
        "\n",
        "First for our categorical variables let's look at side by side bar plots:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMd38zdwHxub"
      },
      "outputs": [],
      "source": [
        "# lead Origin\n",
        "fig, axs = plt.subplots(figsize = (15,7.5))\n",
        "sns.countplot(x = \"LeadOrigin\", hue = \"Converted\", data = leads_df)\n",
        "xticks(rotation = 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCh1evxAHxub"
      },
      "outputs": [],
      "source": [
        "# lead source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs1eoQ0uHxub"
      },
      "outputs": [],
      "source": [
        "# Specialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fohOw_GCHxub"
      },
      "outputs": [],
      "source": [
        "# Occupation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6_0ydtLHxub"
      },
      "source": [
        "For our continuous variables we can look at box plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_R21kNGHxuc"
      },
      "outputs": [],
      "source": [
        "# Total Visits\n",
        "sns.boxplot(y = 'TotalVisits', x = 'Converted', data = leads_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po3BqwFcHxuc"
      },
      "outputs": [],
      "source": [
        "# Total Time Spent on Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uyg9cXSHxuc"
      },
      "outputs": [],
      "source": [
        "# Page Views Per Visit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q70NtEZHxuc"
      },
      "source": [
        "What comments can you make about the different variables and their conversion rates?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0O1aS4Hxuc"
      },
      "source": [
        "## Part 7: Model Building\n",
        "\n",
        "Now we have a reasonably good idea about what we want to predict and the relationships in each variable we can start to build a predictive model for our lead score.\n",
        "\n",
        "As we said above we have a binary target that we want to predict and a mix of 7 categorical and continuous variables we can use as predictor variables\n",
        "\n",
        "Because our target is binary (0 or 1)  - this is a **classification** problem, meaning that we want to predict whether a lead will convert or not.\n",
        "\n",
        "So we need to pick a model for classification. The first choice for many binary classification problems is a **logistic regression** model because of its simplicity and interpretability.\n",
        "\n",
        "There are other options like **random forests** or **neural networks** that can provide better accuracy, but depending on the data logistic regression can perform very well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYnuMztDHxuc"
      },
      "source": [
        "### Training-testing split\n",
        "\n",
        "The next part of building a predictive model is to split the data into a **training** set and **testing** set.\n",
        "This lets us withhold data from the model when training so that we can test it's performance on data it has not seen before - just like it will be doing for our lead scoring in real life.\n",
        "\n",
        "- Train 80%\n",
        "- Test 20%\n",
        "\n",
        "We also need to transform the data to get it ready for modelling\n",
        "- Remove the ID label (not useful as a predictor)\n",
        "- Split out the target column\n",
        "- For categorical variables with multiple levels, create dummy features (one-hot encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHWWv0uAHxud"
      },
      "outputs": [],
      "source": [
        "# package for training models\n",
        "from sklearn import datasets, linear_model, metrics\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPGacAAGHxud"
      },
      "outputs": [],
      "source": [
        "# vector to store conversion results\n",
        "y = leads_df['Converted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZA5Lwy6Hxud"
      },
      "outputs": [],
      "source": [
        "# use the get_dummies variable on Occupation column\n",
        "pd.get_dummies(leads_df['Occupation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOnxiJJdHxud"
      },
      "outputs": [],
      "source": [
        "# taking catagorical variables and creating dummy variables\n",
        "# here we have subsetted the dataframe to only the catagorical columns\n",
        "dummy1 = pd.get_dummies(leads_df[['LeadOrigin', 'LeadSource', 'Specialization', 'Occupation']], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU0lbTzuHxud"
      },
      "outputs": [],
      "source": [
        "# look at dummies dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezTYH8deHxue"
      },
      "outputs": [],
      "source": [
        "# Adding the results of the dummy variables and remaining continous variables\n",
        "# in a dataframe with all the predictors\n",
        "X = pd.concat([leads_df[['TotalVisits', 'TotalTime', 'PageViews']], dummy1], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kMYRtXsHxue"
      },
      "outputs": [],
      "source": [
        "# look at new X dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMZs08PUHxue"
      },
      "outputs": [],
      "source": [
        "# create training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 404)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlBQ7PQBHxue"
      },
      "outputs": [],
      "source": [
        "# print the dimensions of X_train, X_test, y_train and y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqfuQdhHxue"
      },
      "source": [
        "Now we are ready to 'fit' our logistic regresion model to the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do0scaV5Hxuf"
      },
      "outputs": [],
      "source": [
        "# fit a model\n",
        "lm = linear_model.LogisticRegression()\n",
        "model = lm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_BxiN4FHxuf"
      },
      "source": [
        "Easy as that! Two lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOsJ6fWfHxuf"
      },
      "source": [
        "## Part 8: Model Evaluation\n",
        "\n",
        "Next is the important bit - how good is our model at predicting conversions?\n",
        "\n",
        "There are many metrics to evaluate a model and two ways we can get estimates\n",
        "- 'in-sample' evaluating on our training data\n",
        "- 'out of sample' evaluating on our testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgBvdL7iHxuf"
      },
      "outputs": [],
      "source": [
        "# in sample accuracy\n",
        "metrics.accuracy_score(y_train, model.predict(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk1EIiUXHxuf"
      },
      "outputs": [],
      "source": [
        "# Get predictions on testing dataset\n",
        "y_test_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QNCG_UnHxuf"
      },
      "outputs": [],
      "source": [
        "# Can you do the same for the out of of sample accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26YkwIUaHxug"
      },
      "source": [
        "The in-sample estimate always tends to be higher accuracy - which is why we need to evaluate our model on data it has not seen before to get a true estimate of real life performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0hi-LlwHxug"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "For classification models we can use a tool called a **confusion matrix** to see how the model performed on classifying non-conversions compared to conversions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvW4L6G1Hxug"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "# imput is the actual conversions vs the predicted conversions for each lead in the test set\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "confusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu5VLz_RHxug"
      },
      "source": [
        "One thing we are interested in is how many leads predicted as converters were actually converters and how many predicted as non-converters were actually non converters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2XYSp7CHxug"
      },
      "outputs": [],
      "source": [
        "# some more things we can calculate from our confusion matrix\n",
        "TP = confusion[1,1] # true positive\n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives\n",
        "\n",
        "print(\"True positive\", TP)\n",
        "print(\"True negative\", TN)\n",
        "print(\"False Positives\", FP)\n",
        "print(\"False Negatives\", FN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMCLTEw_Hxuh"
      },
      "source": [
        "And the proportions of each:\n",
        "\n",
        "- **Sensitivity** (also called the true positive rate, the recall) measures the proportion of actual positives that are correctly identified as such.\n",
        "\n",
        "- **Specificity** (also called the true negative rate) measures the proportion of actual negatives that are correctly identified as such."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVwEbfd5Hxuh"
      },
      "outputs": [],
      "source": [
        "# Let's see the sensitivity of our logistic regression model\n",
        "se = TP / float(TP+FN)\n",
        "# Let us calculate specificity\n",
        "sp = TN / float(TN+FP)\n",
        "\n",
        "# Out of all those who were converters - what proportion did our model get right?\n",
        "print(\"Sensitivity\", se)\n",
        "# Out of all those who were non-converters - what proportion did our model get right?\n",
        "print(\"Specificity\", sp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HqPbHSAHxuh"
      },
      "source": [
        "The default for predictions is all p > 0.5 are classed as 1 (i.e. conversion) and all p < 0.5 are classed as 0 (non-conversion)\n",
        "\n",
        "Depending on what is worse\n",
        "- Mis-classifying a non-converter as a converter and calling them by mistake - low specificity\n",
        "- Mis-classifying a converter as a non-converter and and not calling them - low sensitivity\n",
        "\n",
        "We can tune the sensitivity and specificity of our model, by moving this threshold of 0.5 higher or lower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDQt8KFlHxuh"
      },
      "outputs": [],
      "source": [
        "# roc curve\n",
        "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
        "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.xlabel(\"False Positive Rate (1-Specificity)\")\n",
        "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty9Wo1bUHxuh"
      },
      "source": [
        "## Part 9: Interpreting Results & Lift\n",
        "\n",
        "The great thing about logistic regression is it gives us the predicted probabilities of that observation falling into that class (in our case conversion = 0 or conversion = 1).\n",
        "\n",
        "We can use this to rank our leads into deciles of the 'hottest' and compare the number of actual conversions in each decile.\n",
        "\n",
        "Then we can see how this compares to the existing method - or no method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro97tG7bHxuh"
      },
      "outputs": [],
      "source": [
        "# create dataframe\n",
        "probs = pd.concat([y_test.reset_index(drop = True), pd.Series(y_pred_proba)], axis = 1)\n",
        "probs.columns = ['actual', 'prob_c']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jjNhMFeHxui"
      },
      "outputs": [],
      "source": [
        "# look at probs dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYW-mmOPHxui"
      },
      "outputs": [],
      "source": [
        "# cut data into decilies\n",
        "# i.e. putting the leads into buckets of top 10%, 20%, ... based on how likely they are to convert\n",
        "probs['deciles'] = pd.qcut(probs.prob_c.rank(method='first'), 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmcXi9rgHxui"
      },
      "outputs": [],
      "source": [
        "# use value_counts() to look at new decile column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjXnEIQcHxui"
      },
      "outputs": [],
      "source": [
        "# compare actual conversion in each decile\n",
        "# pandas groupby is a useful function for\n",
        "lift = probs.groupby(probs.deciles)['actual'].agg([\"sum\", \"count\"]).reset_index()\n",
        "\n",
        "# existing conversion rate in test data\n",
        "x = sum(lift['sum'])/sum(lift['count'])\n",
        "\n",
        "# calculate conversion probs\n",
        "lift['prob_con'] = lift['sum']/lift['count']\n",
        "\n",
        "# get cumulative counts and probabilities\n",
        "lift['sum_c'] = lift['sum'].iloc[::-1].cumsum()\n",
        "lift['prop_c'] = lift['sum_c']/731\n",
        "\n",
        "# old model - 40% conversion by random selection\n",
        "lift['old'] = lift['count']*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whRbnQJjHxuj"
      },
      "outputs": [],
      "source": [
        "# dataframe with our metrics\n",
        "lift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmpjVxYqHxuj"
      },
      "source": [
        "### Waterfall Plot\n",
        "\n",
        "This plot shows us for each decile (ordered 'hottest' to 'not hot' leads) how many conversions we would expect to get by contacting leads in each decile compared to when we just pick leads at random that have a 38% conversion rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6n1UldMRHxuj"
      },
      "outputs": [],
      "source": [
        "# Waterfall analysis plot\n",
        "ax = plt.gca()\n",
        "\n",
        "ax.bar(lift.index, lift['count'].iloc[::-1], color = 'lightgreen')\n",
        "ax.bar(lift.index, lift['sum'].iloc[::-1])\n",
        "ax.plot(lift.index, lift['old'].iloc[::-1], color = 'red')\n",
        "plt.xticks(lift.index, labels=lift.index+1)\n",
        "plt.title(\"Waterfall Analysis\")\n",
        "plt.xlabel(\"Deciles\")\n",
        "plt.ylabel(\"Conversions\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnsa8n2cHxuj"
      },
      "source": [
        "We can see that our model puts our more likely converters in the top deciles. This means that the sales team has a way of prioritising leads\n",
        "1. Top 10% of leads are 98% likely to convert so they should always be at the top of the queue\n",
        "2. Middle % of leads might still convert but less of a priority\n",
        "3. Bottom 30% of leads are very unlikely to convert - don't waste time and resource here! Ignore them!\n",
        "\n",
        "*Next idea - can you work out those in the top decile who might convert on without even needing a sales call? - AB testing*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9atMUEfBHxuj"
      },
      "source": [
        "### Lift plot\n",
        "\n",
        "Here we compare the cumulative gains in converted customers we get from our model compared to what we get by calling leads randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1UVBXmKHxuk"
      },
      "outputs": [],
      "source": [
        "# Lift plot\n",
        "ax = plt.gca()\n",
        "\n",
        "d = np.linspace(0.1,1,10).round(1)\n",
        "\n",
        "ax.plot(lift.index, lift['prop_c'].iloc[::-1]*100, marker='o')\n",
        "ax.plot(lift.index, d*100, color = 'red', marker='o')\n",
        "plt.xticks(lift.index, labels=d*100)\n",
        "plt.title(\"Lift Chart\")\n",
        "plt.xlabel(\"% of Leads\")\n",
        "plt.ylabel(\"% of Conversions\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R3KPcd3Hxuk"
      },
      "source": [
        "This chart shows us that by contacting just the top 10% of leads we actually capture 24% of all conversions.\n",
        "\n",
        "This is compared to having no model where we will only get 10% of all conversions for every 10% of leads we contact.\n",
        "\n",
        "We only need to contact the top 70% leads from our model to capture 95% of all conversions.\n",
        "\n",
        "This model shows we can convert more leads without making more calls! We just have to call the right people in the right order!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxwRzDFrHxuk"
      },
      "source": [
        "# Part 10: Next steps\n",
        "\n",
        "You could try improve model accuracy by:\n",
        "- Try a different model\n",
        "- Transform variables\n",
        "- Variable selection\n",
        "- Tune hyperparameters\n",
        "- Adding new data\n",
        "\n",
        "Model building is an iterative process until you reach the level of accuracy required"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}